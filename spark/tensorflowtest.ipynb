{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.4.4.dev0\n",
              "None"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%pyspark\n",
        "import pyspark \n",
        "print(print(pyspark.__version__)) \n",
        "# new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.14.0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf; \n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "\n",
        "# Import data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
              "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
              "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
              "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
              "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
              "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
              "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
              "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist = input_data.read_data_sets('/tmp/data', one_hot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "W = tf.Variable(tf.zeros([784, 10]))\n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "y = tf.matmul(x, W) + b "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_ = tf.placeholder(tf.float32, [None, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean_1:0' shape=() dtype=float32>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)), reduction_indices=[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "summary = tf.summary.scalar(\"accuracy\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dbutils' is not defined",
          "output_type": "error",
          "traceback": [
            "NameError : name 'dbutils' is not defined",
            "Traceback (most recent call last):\n",
            "NameError: name 'dbutils' is not defined\n"
          ]
        }
      ],
      "source": [
        "log_dir = \"/tmp/tensorflow_log_dir\"\n",
        "dbutils.tensorboard.start(log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# Make sure to use the same log directory for both start TensorBoard in your training.\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=sess.graph)\n",
        "\n",
        "tf.global_variables_initializer().run()\n",
        "for batch in range(1000):\n",
        "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "  _, batch_summary = sess.run([train_step, summary], feed_dict={x: batch_xs, y_: batch_ys})\n",
        "  summary_writer.add_summary(batch_summary, batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.918"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
        "                                    y_: mnist.test.labels}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dbutils' is not defined",
          "output_type": "error",
          "traceback": [
            "NameError : name 'dbutils' is not defined",
            "Traceback (most recent call last):\n",
            "NameError: name 'dbutils' is not defined\n"
          ]
        }
      ],
      "source": [
        "dbutils.tensorboard.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "ename": "PermissionError",
          "evalue": "[Errno 13] Permission denied: '/dbfs'",
          "output_type": "error",
          "traceback": [
            "PermissionError : [Errno 13] Permission denied: '/dbfs'",
            "Traceback (most recent call last):\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/shutil.py\", line 555, in move\n    symlinks=True)\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/shutil.py\", line 315, in copytree\n    os.makedirs(dst)\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/os.py\", line 210, in makedirs\n    makedirs(head, mode, exist_ok)\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/os.py\", line 210, in makedirs\n    makedirs(head, mode, exist_ok)\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/os.py\", line 220, in makedirs\n    mkdir(name, mode)\n",
            "PermissionError: [Errno 13] Permission denied: '/dbfs'\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.move(log_dir, \"/dbfs/tensorflow/logs\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
